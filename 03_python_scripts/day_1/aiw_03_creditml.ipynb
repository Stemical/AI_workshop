{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0200c1-3720-4646-aba3-ceb8c13b457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Artificial Intelligence Workshop RUG\n",
    "# -----------------------------------------------------------\n",
    "# R.M. (Rolando) Gonzales Martinez\n",
    "# -----------------------------------------------------------\n",
    "# ~~~~~~~ Credit scoring model with Machine Learning ~~~~~~~~\n",
    "#       confusion matrix, elastic nets regularization\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "df = pd.read_excel(\"bankloans.xlsx\")\n",
    "print(df.head())\n",
    "# age: Age in years\n",
    "# education: Level of education, (1) did not complete high school, (2) high school degree, (3) some college, (4) college degree, (5) postundergraduate degree\n",
    "# employears: Years with current employer\n",
    "# address: Years at current address\n",
    "# salary: salary in thousands\n",
    "# creddebt: Credit card debt in thousands\n",
    "# othdebt: Other debt in thousands\n",
    "# default: credit default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3d93d-9d5a-4e60-9246-de1175b1eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "#  Machine learning logic: train and test partition\n",
    "# ---------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Convert categorical variable to dummy (one-hot encoding) for modeling\n",
    "df_encoded = pd.get_dummies(df, columns=['education'], drop_first=True)\n",
    "\n",
    "# Define predictors and target\n",
    "X = df_encoded.drop(columns=['default'])\n",
    "y = df_encoded['default']\n",
    "\n",
    "# Split into train and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the logit model on the training data\n",
    "train_data = X_train.copy()\n",
    "train_data['default'] = y_train\n",
    "formula = \"default ~ \" + \" + \".join(X_train.columns)\n",
    "logit_model = smf.logit(formula=formula, data=train_data).fit()\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_prob = logit_model.predict(X_test)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluate model performance\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Credit Default Prediction\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print AUC and Gini with 2 decimals\n",
    "print(['AUC: ', round(auc_score,4)])\n",
    "print(['Gini: ', round(2 * auc_score- 1,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811df3a5-9853-4182-922d-976dca24e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "#   confusion matrix of the ML credit scoring model\n",
    "# ---------------------------------------------------\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute Youden's J statistic for each threshold\n",
    "youden_j = tpr - fpr\n",
    "optimal_index = np.argmax(youden_j)\n",
    "optimal_threshold = thresholds[optimal_index]\n",
    "optimal_tpr = tpr[optimal_index]\n",
    "optimal_fpr = fpr[optimal_index]\n",
    "\n",
    "# Predict probabilities for test dataset and classify using optimal threshold\n",
    "test_df = X_test.copy()\n",
    "test_df[\"default\"] = y_test\n",
    "test_df[\"probab_score\"] = logit_model.predict(X_test)\n",
    "test_df[\"predicted_default\"] = (test_df[\"probab_score\"] >= optimal_threshold).astype(int)\n",
    "\n",
    "# Create a confusion matrix based only on the test set\n",
    "conf_matrix_test = confusion_matrix(test_df[\"default\"], test_df[\"predicted_default\"])\n",
    "\n",
    "# Format confusion matrix as DataFrame\n",
    "conf_matrix_test_df = pd.DataFrame(conf_matrix_test, \n",
    "                                   index=[\"Actual Non-Default\", \"Actual Default\"], \n",
    "                                   columns=[\"Predicted Non-Default\", \"Predicted Default\"])\n",
    "\n",
    "conf_matrix_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9850898-2d2c-484a-bbdb-4bc697fa32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "#   ML credit scoring model based on Elastic Nets\n",
    "# ---------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split standardized data\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit logistic regression model with L1 regularization (Lasso)\n",
    "logit_EN_model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, random_state=666, max_iter=10000)\n",
    "logit_EN_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities and classes\n",
    "y_pred_prob_EN = logit_EN_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_class_EN = (y_pred_prob_EN > 0.5).astype(int)\n",
    "\n",
    "# Evaluate model performance\n",
    "auc_score_EN = roc_auc_score(y_test, y_pred_prob_EN)\n",
    "\n",
    "# ROC Curve\n",
    "fpr_EN, tpr_EN, thresholds_EN = roc_curve(y_test, y_pred_prob_EN)\n",
    "plt.figure()\n",
    "plt.plot(fpr_EN, tpr_EN, label=f\"ROC Curve (AUC = {auc_score_EN:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for L1-Regularized Logistic Regression\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print AUC and Gini \n",
    "print(['AUC: ', round(auc_score_EN,4)])\n",
    "print(['Gini: ', round(2 * auc_score_EN - 1,4)])\n",
    "\n",
    "# Compute Youden's J statistic for each threshold\n",
    "youden_j_EN = tpr_EN - fpr_EN\n",
    "optimal_index_EN = np.argmax(youden_j_EN)\n",
    "optimal_threshold_EN = thresholds_EN[optimal_index]\n",
    "optimal_tpr_EN = tpr[optimal_index_EN]\n",
    "optimal_fpr_EN = fpr[optimal_index_EN]\n",
    "\n",
    "# Reconstruct X_test_scaled into a DataFrame\n",
    "test_df_EN = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Now you can safely assign the target and predictions\n",
    "test_df_EN[\"default\"] = y_test.values\n",
    "test_df_EN[\"probab_score\"] = logit_EN_model.predict_proba(X_test_scaled)[:, 1]\n",
    "test_df_EN[\"predicted_default\"] = (test_df_EN[\"probab_score\"] >= optimal_threshold_EN).astype(int)\n",
    "\n",
    "\n",
    "# Create a confusion matrix based only on the test set\n",
    "conf_matrix_test_EN = confusion_matrix(test_df_EN[\"default\"], test_df_EN[\"predicted_default\"])\n",
    "\n",
    "# Format confusion matrix as DataFrame\n",
    "conf_matrix_test_df_EN = pd.DataFrame(conf_matrix_test_EN, \n",
    "                                   index=[\"Actual Non-Default\", \"Actual Default\"], \n",
    "                                   columns=[\"Predicted Non-Default\", \"Predicted Default\"])\n",
    "\n",
    "conf_matrix_test_df_EN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
