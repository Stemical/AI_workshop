{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01255ce-780b-4140-abfe-5a994311097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " -----------------------------------------------------------\n",
    "          Artificial Intelligence Workshop RUG\n",
    " -----------------------------------------------------------\n",
    "            R.M. (Rolando) Gonzales Martinez\n",
    " -----------------------------------------------------------\n",
    " ~~~~~~~ Credit scoring model with Machine Learning ~~~~~~~~\n",
    "    support vector machines with k-fold cross-validation\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_excel(\"b.xlsx\") # <-------------------- fill here\n",
    "print(df.head())\n",
    "# age: Age in years\n",
    "# education: Level of education, (1) did not complete high school, (2) high school degree, (3) some college, (4) college degree, (5) postundergraduate degree\n",
    "# employears: Years with current employer\n",
    "# address: Years at current address\n",
    "# salary: salary in thousands\n",
    "# creddebt: Credit card debt in thousands\n",
    "# othdebt: Other debt in thousands\n",
    "# default: credit default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a78bc-bba3-42f8-a6bf-c912d4ad49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machines with cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2. Preprocessing\n",
    "y = df['default'].astype(int)\n",
    "X = df[['age', 'employears', 'salary', 'creddebt', 'education']]\n",
    "num_cols = ['age', 'employears', 'salary', 'creddebt']\n",
    "cat_cols = []\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "])\n",
    "\n",
    "# 3. Define pipelines\n",
    "'''\n",
    "In SVM:\n",
    "    C is the regularization parameter that controls the trade-off between maximizing the margin and minimizing classification errors.\n",
    "    Small C → Wider margin, allows more misclassifications (stronger regularization, simpler model).\n",
    "    Large C → Narrower margin, penalizes misclassifications more (weaker regularization, fits training data tightly, risk of overfitting).\n",
    "    C interacts with gamma (for RBF/poly/sigmoid kernels):\n",
    "        High C + High gamma → Very complex boundaries (overfitting risk).\n",
    "        Low C + Low gamma → Smoother boundaries (underfitting risk).\n",
    "    If kernel='linear', C is the main tunable parameter.\n",
    "'''\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('svm', SVC(kernel='', C=, gamma='scale', probability=True)) # <-------------------- fill here\n",
    "])\n",
    "logit_pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('logit', LogisticRegression(solver='lbfgs', C=1.0, max_iter=1000))\n",
    "])\n",
    "\n",
    "models = [\n",
    "    ('SVM', svm_pipeline),\n",
    "    ('Logistic', logit_pipeline)\n",
    "]\n",
    "\n",
    "# 4. Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits= , shuffle=True, random_state=) # <-------------------- fill here\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro'\n",
    "}\n",
    "\n",
    "# 5. Run cross-validation\n",
    "results = []\n",
    "for name, pipeline in models:\n",
    "    cv_res = cross_validate(\n",
    "        pipeline, X, y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Acc (mean ± std)': f\"{cv_res['test_accuracy'].mean():.3f} ± {cv_res['test_accuracy'].std():.3f}\",\n",
    "        'AUC (mean ± std)': f\"{cv_res['test_roc_auc'].mean():.3f} ± {cv_res['test_roc_auc'].std():.3f}\",\n",
    "        'Precision (mean ± std)': f\"{cv_res['test_precision_macro'].mean():.3f} ± {cv_res['test_precision_macro'].std():.3f}\",\n",
    "        'Recall (mean ± std)':    f\"{cv_res['test_recall_macro'].mean():.3f} ± {cv_res['test_recall_macro'].std():.3f}\",\n",
    "        'F1 (mean ± std)':        f\"{cv_res['test_f1_macro'].mean():.3f} ± {cv_res['test_f1_macro'].std():.3f}\"\n",
    "    })\n",
    "\n",
    "df_cv_comparison = pd.DataFrame(results)\n",
    "\n",
    "df_cv_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15931546-bf49-4d5d-a237-3d4c6a07fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "plt.figure()\n",
    "for name, pipeline in models:              # <-- loop directly over the list, not .items()\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(roc_auc_score(y_test, y_prob))\n",
    "    # Compute mean and std\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    # Plot mean ROC\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'{name} (AUC = {mean_auc:.3f} ± {std_auc:.3f})')\n",
    "    # Shade std interval\n",
    "    plt.fill_between(mean_fpr, \n",
    "                     np.clip(mean_tpr - std_tpr, 0, 1),\n",
    "                     np.clip(mean_tpr + std_tpr, 0, 1),\n",
    "                     alpha=0.2)\n",
    "\n",
    "# Baseline\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Baseline')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Cross-Validated ROC Curves with ±1 STD')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
